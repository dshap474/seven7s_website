{
  "class": "crypto",
  "name": "Empire",
  "title": "Inside AI's GPU Economy & Infrastructure Boom | Sam Hogan, Kuzco",
  "text": "Synopsis\nThe AI compute market is transitioning from training-focused to inference-focused, with a massive opportunity emerging for distributed, cost-effective AI compute marketplaces that can aggregate idle GPU capacity across global networks.\n\nKey Insights\n- Historically, 95% of AI compute was used for training, but this is rapidly shifting towards inference, potentially reaching 95% inference compute in the next few years\n- Cusco is building a spot market for AI inference, currently connecting approximately 5,000 GPUs globally\n- GPU pricing for AI compute has dramatically dropped, from $8/hour to under $3/hour, with continued downward price pressure expected\n- Nvidia's GPU strategy involves creating scarcity narratives while gradually increasing supply, impacting market dynamics\n- Inference compute is becoming more critical as AI models become more practically useful for real-world applications\n- Open-source models, particularly from Meta, are playing a crucial role in democratizing AI compute access\n- The future of AI compute marketplaces involves creating global trading venues for AI tokens and compute resources\n- Distributed GPU networks can offer significant cost advantages, potentially reducing inference costs by up to 10x compared to centralized providers\n- Cryptocurrency and stable coins are becoming integral to facilitating cross-border payments and verification in distributed compute networks"
}